learning rate = 0.01
start point = [0.1, 1]

results: 
1: [0.08, 0.98] = 1.0244
2: [0.047995999999999955, 0.9443959999999999] = 0.9149199649759998
3: [0.015954696783967715, 0.9005415557247965] = 0.8135206170819204
4: [-0.011117220496571465, 0.849845193421599] = 0.7234727786974889
5: [-0.03266972580820815, 0.7883241380884112] = 0.6321280565366715
6: [-0.047500219350345645, 0.7115734311423648] = 0.5288994562910273
7: [-0.0529076087554566, 0.6201930773950793] = 0.4126316038909835
8: [-0.047235537084470904, 0.5248236198054615] = 0.2977517915422919
9: [-0.03353319202797386, 0.4427801485095087] = 0.2072990095899523
10: [-0.018347729873887008, 0.3831571674033391] = 0.15017580684780168
11: [-0.0057946980670368405, 0.34061461751840555] = 0.1163541029240909
12: [0.003667589348691472, 0.3056620644304341] = 0.0935638097481812
13: [0.010446314404180777, 0.2717995001591704] = 0.07496622313308483
14: [0.014421465016912584, 0.23606923062518215] = 0.057808468180305765
15: [0.015125017981243669, 0.19909882806044] = 0.041928005024370094
16: [0.012674769086864202, 0.16491455859255855] = 0.028803309349831708
17: [0.008444240984835236, 0.13796072435222478] = 0.01974621352189026
18: [0.004196871855797229, 0.11890048374260456] = 0.0143134623679652
19: [0.0007765289290680545, 0.10494027337351591] = 0.01101849094748505
20: [-0.0017608988287487527, 0.09311878086372784] = 0.008702114996397852
21: [-0.003466842213029399, 0.08166792047980152] = 0.006789839184795611
22: [-0.004268645982624518, 0.06999846801831562] = 0.005081998910160919
23: [-0.0040996181684600196, 0.05863335439852145] = 0.0036059389392942894
24: [-0.0031509844922965858, 0.04880646514050786] = 0.002481358072218545
25: [-0.0018953021425908313, 0.04135093665933832] = 0.0017458216647217037
26: [-0.0007464050283955252, 0.035953065005219734] = 0.0012981940879336971
27: [0.0001515519207368961, 0.031716494083622676] = 0.0010061656768032626
28: [0.0007926990690694531, 0.027914220059482978] = 0.0007854873996702775
29: [0.0011696229899240734, 0.024180409019059372] = 0.0005983723597145971
30: [0.0012586617415721638, 0.02049752360050937] = 0.0004359907675504134
31: [0.0010783302338500651, 0.01713423977844249] = 0.0003052101337175123
32: [0.0007349167878347438, 0.01440899429439439] = 0.00021302014342630346
33: [0.00036872038667306987, 0.012381193074418408] = 0.00015465348918150974
34: [6.138518236981734e-05, 0.01084006558826322] = 0.0001175447033639942
35: [-0.0001679808347253561, 0.00953467504138176] = 9.119220375309854e-05
36: [-0.00031675815298089574, 0.008306039535902587] = 6.999365004677556e-05
37: [-0.0003788384544347524, 0.0071040745248120065] = 5.190306059966806e-05
38: [-0.00035399245024942777, 0.005976075049259519] = 3.6966579542718094e-05
39: [-0.00026470138143964327, 0.005016997256357585] = 2.587092968366009e-05
40: [-0.00015220796657727472, 0.004276995433892729] = 1.852436259243514e-05
41: [-4.971404711870398e-05, 0.003717482424442963] = 1.3844390440851537e-05
42: [3.0185325729784193e-05, 0.003261240781391779] = 1.0644802973106992e-05
43: [8.507637941013911e-05, 0.0028481040354156662] = 8.184076499886383e-06
44: [0.00011327396816801317, 0.002450847962860142] = 6.134965655700988e-06
45: [0.00011388368850044769, 0.0020740735656383084] = 4.431476100744276e-06
46: [9.157523264553951e-05, 0.0017432190808922242] = 3.1226729963275778e-06
